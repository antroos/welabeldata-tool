'use client';

import { useState, useEffect } from 'react';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';

type Model = {
  id: string;
  name: string;
  provider: 'openai';
};

// Обновленный список актуальных моделей
const openaiModels: Model[] = [
  { id: 'gpt-4o', name: 'GPT-4o', provider: 'openai' },
  { id: 'gpt-4', name: 'GPT-4', provider: 'openai' },
  { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo', provider: 'openai' },
  { id: 'gpt-4-turbo', name: 'GPT-4 Turbo', provider: 'openai' },
];

export default function Chat() {
  const [messages, setMessages] = useState<Array<{ role: 'user' | 'assistant' | 'system', content: string }>>([]);
  const [input, setInput] = useState('');
  const [selectedModel, setSelectedModel] = useState<Model>(openaiModels[0]);
  const [isLoading, setIsLoading] = useState(false);
  const [modelInfo, setModelInfo] = useState<string | null>(null);
  const [errorMessage, setErrorMessage] = useState<string | null>(null);
  const [availableModels, setAvailableModels] = useState<any[]>([]);

  // При первой загрузке выполняем запрос к API для получения информации о моделях
  useEffect(() => {
    const fetchModelInfo = async () => {
      try {
        const response = await fetch('/api/models');
        if (response.ok) {
          const data = await response.json();
          // Сохраняем доступные модели
          setAvailableModels(data);
          console.log('Available models:', data);
        } else {
          console.error('Error fetching models: HTTP', response.status);
          const errorData = await response.json();
          console.error('Error details:', errorData);
        }
      } catch (error) {
        console.error('Error fetching models:', error);
      }
    };

    fetchModelInfo();
  }, []);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim()) return;

    const userMessage = { role: 'user' as const, content: input };
    const newMessages = [...messages, userMessage];
    setMessages(newMessages);
    setInput('');
    setIsLoading(true);
    setModelInfo(null);
    setErrorMessage(null);

    try {
      console.log(`Sending request with model: ${selectedModel.id}`);
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: newMessages.map(msg => ({ role: msg.role, content: msg.content })),
          model: selectedModel.id,
        }),
      });

      if (!response.ok) {
        // Пытаемся получить детали ошибки из ответа
        let errorDetails = 'Network response was not ok: ' + response.status;
        try {
          const errorData = await response.json();
          errorDetails = errorData.details || errorData.error || errorDetails;
        } catch (e) {
          // Если не удалось распарсить JSON
        }
        throw new Error(errorDetails);
      }

      const data = await response.json();
      
      if (data.error) {
        throw new Error(data.error);
      }

      // Обновим информацию о модели, которая действительно использовалась
      if (data.model) {
        setModelInfo(`Response generated by: ${data.model}`);
      }

      const assistantMessage = { 
        role: 'assistant' as const, 
        content: data.content || 'Sorry, I could not generate a response.'
      };
      setMessages([...newMessages, assistantMessage]);
    } catch (error) {
      console.error('Error:', error);
      const errorMsg = error instanceof Error ? error.message : 'Unknown error occurred';
      setErrorMessage(errorMsg);
      setMessages([...newMessages, { 
        role: 'assistant' as const, 
        content: `Sorry, there was an error processing your request: ${errorMsg}`
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="container mx-auto max-w-4xl p-4">
      <div className="flex flex-col h-screen">
        {/* Header with model selector */}
        <div className="mb-4">
          <select
            value={selectedModel.id}
            onChange={(e) => {
              const model = openaiModels.find(m => m.id === e.target.value);
              if (model) setSelectedModel(model);
            }}
            className="w-full p-2 border rounded-lg bg-white"
          >
            {openaiModels.map((model) => (
              <option key={model.id} value={model.id}>
                {model.name}
              </option>
            ))}
          </select>
          {modelInfo && (
            <div className="text-sm text-gray-500 mt-1">{modelInfo}</div>
          )}
          {errorMessage && (
            <div className="text-sm text-red-500 mt-1">Error: {errorMessage}</div>
          )}
        </div>

        {/* Chat messages */}
        <div className="flex-1 overflow-y-auto mb-4 space-y-4">
          {messages.map((message, index) => (
            <div
              key={index}
              className={`p-4 rounded-lg ${
                message.role === 'user' ? 'bg-blue-100 ml-12' : 'bg-gray-100 mr-12'
              }`}
            >
              {message.content}
            </div>
          ))}
          {isLoading && (
            <div className="bg-gray-100 p-4 rounded-lg mr-12">
              <div className="animate-pulse">Thinking...</div>
            </div>
          )}
        </div>

        {/* Input form */}
        <form onSubmit={handleSubmit} className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            placeholder="Type your message..."
            className="flex-1 p-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
          />
          <button
            type="submit"
            disabled={isLoading}
            className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-blue-300"
          >
            Send
          </button>
        </form>
      </div>
    </div>
  );
} 